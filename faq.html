
<div class="panel-group" id="accordion">
  <div class="panel panel-default">
    <div class="panel-heading">
      <h4 class="panel-title">
        <a class="collapsible-link" data-toggle="collapse" 
           data-parent="#accordion" href="#collapse1">
          What is statcheck?
        </a>
      </h4>
    </div>
    <div id="collapse1" class="panel-collapse collapse">
      <div class="panel-body">
        <p>
          statcheck is a "spellchecker" for statistics. It checks whether your 
          <i>p</i>-values match their accompanying test statistic and degrees 
          of freedom.
        </p>
      </div>
    </div>
  </div>
  <div class="panel panel-default">
    <div class="panel-heading">
      <h4 class="panel-title">
        <a class="collapsible-link" data-toggle="collapse" data-parent="#accordion" href="#collapse2">
          How does it work?
        </a>
      </h4>
    </div>
    <div id="collapse2" class="panel-collapse collapse">
      <div class="panel-body">
        <p>
  		    statcheck works in roughly 3 steps:
  	    </p>
        <ol>
      		<li>
      			<b>Search for statistics</b><br> It scans the text for null-hypothesis 
      			significance test (NHST) results that are reported 1) completely (test 
      			statistic, degrees of freedom, and <i>p</i>-value), and 2) in APA style.
      		</li>
      		<li>
      			<b>Recalculate <i>p</i>-value</b><br> Using the reported test statistic and 
      			degrees of freedom, statcheck recalculates the <i>p</i>-value. By 
      			default, the recalculated <i>p</i>-value is two-sided.
      		</li>
      		<li>
      			<b>Flag inconsistencies</b><br> statcheck compares the reported 
      			<i>p</i>-value with the recomputed <i>p</i>-value. If these two don't 
      			match, statcheck will flag the result as an error.
      		</li>
      	</ol>
      	<p>
      	  For example, say that you reported the following result:
      	</p> 
      	<p>
      	  <i>The difference was significant, <i>t</i>(28) = 1.2, <i>p</i> < .05.</i>
      	</p>
      	<p>
      	  If you click "Run statcheck", statcheck will recognize this as a 
      		statistical test. It will take the degrees of freedom (28) and test 
      		statistic (2.2) and recalculate the <i>p</i>-value: <i>p</i> = .24. 
      		This <i>p</i>-value does not match the reported <i>p</i>-value, so 
      		statcheck will flag this result as an error.
      	</p>
      </div>
    </div>
  </div>
  <div class="panel panel-default">
    <div class="panel-heading">
      <h4 class="panel-title">
        <a class="collapsible-link" data-toggle="collapse" data-parent="#accordion" href="#collapse3">
          How do I correct the inconsistency?
        </a>
      </h4>
    </div>
    <div id="collapse3" class="panel-collapse collapse">
      <div class="panel-body">
        <p>
          If you click on a result that statcheck flagged as an error, you can see 
    		  the recalculated <i>p</i>-value. Click on "Go to test" to jump to the location of 
    		  the test in your document.
    		</p>
    	  <p>
    	    To fix any errors, go to your statistical software to check which of the 
    		  three numbers (test statistic, degrees of freedom, and/or <i>p</i>-value) you 
    		  need to correct.
    		</p>
      </div>
    </div>
  </div>
  <div class="panel panel-default">
    <div class="panel-heading">
      <h4 class="panel-title">
        <a class="collapsible-link" data-toggle="collapse" 
           data-parent="#accordion" href="#collapse4">
          Which results does statcheck detect?
        </a>
      </h4>
    </div>
    <div id="collapse4" class="panel-collapse collapse">
      <div class="panel-body">
        <p>
          statcheck searches for specific patterns and recognizes statistical 
  	  	  results from correlations and t, F, &chi;&sup2;, Z tests and Q tests. 
  	  	  statcheck can only read these results if the results are reported 
  	  	  exactly according to the APA guidelines:
  	  	</p>
      	<ul>
        	<li>
        	  t(df) = value, p = value
        	</li>
        	<li>
        	  F(df1, df2) = value, p = value
        	</li>
        	<li>
        	  r(df) = value, p = value
        	</li>
        	<li>
        	  &chi;&sup2; (df, N = value) = value, p = value (N is optional, 
        	  &Delta;G is also included, since it follows a &chi;&sup2; 
        	  distribution)
        	</li>
        	<li>
        	  Z = value, p = value
        	</li>
        	<li>
        	  Q (df) = value, p = value (statcheck can read and distinguishes 
        	  between Q, Qw / Q-within, and Qb / Q-between)
        	</li>
    	  </ul>
    	  <p>
    	    statcheck takes into account that test statistics and p values may be 
    		  exactly (=) or inexactly (< or >) reported. Different spacing has 
    		  also been taken into account.
    		</p>
      </div>
    </div>
  </div>
  <div class="panel panel-default">
    <div class="panel-heading">
      <h4 class="panel-title">
        <a class="collapsible-link" data-toggle="collapse" 
           data-parent="#accordion" href="#collapse5">
          What does the correction for one-tailed tests do?
        </a>
      </h4>
    </div>
    <div id="collapse5" class="panel-collapse collapse">
      <div class="panel-body">
        <p>
          By default, statcheck treats all tests as two-tailed. If you want to 
          take into account one-tailed tests, you can check the box "Try to 
          correct for one-tailed tests?".
  	  	</p>
      	<p>
      	  When this box is ticked, statcheck will search the entire text for 
      	  the keywords "one-tailed", "one-sided", and "directional" (taking 
      	  spacing issues etc. into account). When statcheck finds at least one 
      	  of those keywords AND an initially inconsistent result would be 
      	  consistent if it was a one-tailed test, then statcheck treats this 
      	  case as a one-tailed test and counts it as consistent.
      	</p>
      	<p>
      	  Note that this correction for one-tailed tests only works if the 
      	  one-tailed tests are explicitly identified as such in the text, with 
      	  one of the keywords mentioned above.
      	</p>
      </div>
    </div>
  </div>
  <div class="panel panel-default">
    <div class="panel-heading">
      <h4 class="panel-title">
        <a class="collapsible-link" data-toggle="collapse" 
           data-parent="#accordion" href="#collapse6">
          Why doesn't statcheck detect my statistics?
        </a>
      </h4>
    </div>
    <div id="collapse6" class="panel-collapse collapse">
      <div class="panel-body">
        <p>
          Some common reasons why statcheck doesn't detect some results:
        </p>
        <ol>
        	<li>
        		the result was not reported according to APA style. This includes 
        		minor deviations such as square brackets instead of parentheses, or 
        		a semi-colon instead of a comma.
        	</li>
        	<li>
        		the result was not reported completely. statcheck needs three 
        		ingredients to detect a result and recalculate the <i>p</i>-value: 
        		the reported test statistic, degrees of freedom, and <i>p</i>-value. 
        		If one or more of these are missing, statcheck will not pick it up.
        	</li>
        	<li>
        		the result is reported in a table.
        	</li>
        </ol>
      </div>
    </div>
  </div>
  <div class="panel panel-default">
    <div class="panel-heading">
      <h4 class="panel-title">
        <a class="collapsible-link" data-toggle="collapse" 
           data-parent="#accordion" href="#collapse7">
          Why does statcheck say it's an error when I think it's not?
        </a>
      </h4>
    </div>
    <div id="collapse7" class="panel-collapse collapse">
      <div class="panel-body">
        <p>
          As a general rule: statcheck flags result as an error when the 
          reported <i>p</i>-value does not match the recalculated 
          <i>p</i>-value. However, there may be cases in which you deliberately 
          reported an inconsistent result. For example:
        </p>
        <ol>
          <li>
            you conducted a one-tailed test, but you did not explicitly state 
            it was a one-tailed test using one of the keywords mentioned above
          </li>
          <li>
            you used a Bonferroni correction on your <i>p</i>-value (i.e., 
            multiplied your <i>p</i>-value by the number of tests) to correct 
            for multiple testing
          </li>
          <li>
            you corrected the degrees of freedom for a violation of an 
            assumption (e.g., sphericity), but reported the unadjusted test 
            statistic and <i>p</i>-value
          </li>
        </ol>
        <p>
          In all these cases, the reported <i>p</i>-value does not match the 
          accompanying test statistic and degrees of freedom anymore, and 
          causes statcheck to flag the result as a potential error.
        </p>
        <p>
          We would like to argue that in these cases, there is no reason to 
          report a result as internally inconsistent. We would advise the 
          following in the scenarios above, respectively:
        </p>
        <ol>
          <li>
            explicitly identify which tests are one-tailed and which are 
            two-tailed. This will increase the transparency and reproducibility 
            of your text.
          </li>
          <li>
            when using a Bonferroni correction, correct your <i>alpha level</i> 
            by dividing it by the number of tests, instead of multiplying the 
            <i>p</i>-value. The latter results in internal inconsistencies, but 
            could also result in impossible <i>p</i>-values larger than 1.
          </li>
          <li>
            when adjusting results for violations of assumptions, report the 
            entire adjusted result, instead of only adjusting one element in 
            the result (i.e., only the test statistic, degrees of freedom, or 
            the <i>p</i>-value).
          </li>
        </ol>
        <p>
          Of course it is also possible that statcheck really made a mistake 
          and erroneously flagged a result as inconsistent. This can happen 
          when statcheck does not correctly read and/or classify the test type 
          of the extracted statistic. If you think that statcheck wrongly 
          flagged one of your results, please contact Michèle (see below).
          
          For more information about statcheck's accuracy, see the next section.
        </p>
      </div>
    </div>
  </div>
  <div class="panel panel-default">
    <div class="panel-heading">
      <h4 class="panel-title">
        <a class="collapsible-link" data-toggle="collapse" 
           data-parent="#accordion" href="#collapse8">
          How accurate is statcheck?
        </a>
      </h4>
    </div>
    <div id="collapse8" class="panel-collapse collapse">
      <div class="panel-body">
        <p>
          In typical psychology journals, statcheck detects about 60% of the 
          null hypothesis significance tests. In classifying extracted results 
          as consistent or inconsistent, statcheck has an accuracy between 
          96.2% and 99.9%, depending on its settings. See 
          <a href="https://psyarxiv.com/tcxaj/"> Nuijten et al., 2017</a>: for 
          details.
        </p>
      </div>
    </div>
  </div>
   <div class="panel panel-default">
    <div class="panel-heading">
      <h4 class="panel-title">
        <a class="collapsible-link" data-toggle="collapse" 
           data-parent="#accordion" href="#collapse10">
          Where can I find more information about statcheck?
        </a>
      </h4>
    </div>
    <div id="collapse10" class="panel-collapse collapse">
      <div class="panel-body">
        <ul>
        	<li>
        	  <a href="https://rpubs.com/michelenuijten/statcheckmanual">The 
        	  manual</a>: a detailed instruction manual with information on what 
        	  statcheck can and cannot do, information on how to install and use 
        	  the statcheck R package, and more.
        	</li>
        	<li>
        	  <a href="http://statcheck.io">The web app</a>: upload a paper in 
        	  one click and get a table of all detected statistics, classified as 
        	  consistent, an inconsistency or a decision inconsistency.
        	</li>
        	<li>
        	  <a href="http://cran.r-project.org/web/packages/statcheck/">The R 
        	  package</a>: the R package has additional functionality which 
        	  allows you to change more settings and to scan entire folders of 
        	  papers.
        	</li>
        	<li>
        	  <a href="https://doi.org/10.3758/s13428-015-0664-2">
        	  The paper</a>: the seminal paper in which statcheck was introduced. 
        	  We ran statcheck on over 30,000 psychology papers and report 
        	  general inconsistency-prevalences over time and per journal.
        	</li>
        	<li>
        	  <a href="https://psyarxiv.com/tcxaj/">The validity study</a>: we 
        	  compared statcheck's performance with manual checks and assessed 
        	  its accuracy in classifying results as consistent/inconsistent
        	</li>
        	<li>
        	  <a href="https://github.com/MicheleNuijten/statcheck">The GitHub 
        	  page</a>: here you can find statcheck's latest developments.
        	</li>
        </ul>
      </div>
    </div>
  </div>
  <div class="panel panel-default">
    <div class="panel-heading">
      <h4 class="panel-title">
        <a class="collapsible-link" data-toggle="collapse" 
           data-parent="#accordion" href="#collapse11">
          How can I contact you?
        </a>
      </h4>
    </div>
    <div id="collapse11" class="panel-collapse collapse">
      <div class="panel-body">
        <p>
  	      You can contact us directly via Twitter at 
  	      <a href="http://twitter.com/MicheleNuijten/">@MicheleNuijten</a> and 
  	      <a href="http://twitter.com/willemsleegers/">@WillemSleegers</a>.
  	    </p>
  	    <p>
  	      For other ways to contact us, see <a href="http://mbnuijten.com/">
  	      Michèle's website</a> or <a href="http://willemsleegers.com/">
  	      Willem's website</a>.
  	    </p>
      </div>
    </div>
  </div>
</div>
